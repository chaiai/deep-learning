{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG network training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNxTUWXaT0CAcHO8taZyI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiai/deep-learning/blob/main/VGG_network_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbZ1oQQtPGwt"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJg1PK53PKKb"
      },
      "source": [
        "# Define a small class MyClass\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        # One class variable 'a' is set to 1\n",
        "        self.var1 = 1\n",
        "\n",
        "# Create an object of type MyClass()\n",
        "my_obj = MyClass()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peg9YehBPQeh",
        "outputId": "c39f2b99-cd8b-4a24-8698-46e0a9ddc7a9"
      },
      "source": [
        "my_obj.__dict__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M7gEu03PR33",
        "outputId": "27bb0208-ef8c-406d-e1e7-9b41949746d5"
      },
      "source": [
        "vars(my_obj)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TZlzWmtPTJm"
      },
      "source": [
        "class Block(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
        "        super(Block, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.repetitions = repetitions\n",
        "        \n",
        "        # Define a Conv2D_0, Conv2D_1, etc. based on number of repetitions\n",
        "        for i in range(self.repetitions):\n",
        "            \n",
        "            # Define a Conv2D layer, specifying filters, kernel_size, activation, and padding.\n",
        "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters, self.kernel_size, activation='relu', padding='same')\n",
        "            \n",
        "        # Define the max pool layer that will be added after the Conv2D blocks\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size, strides=strides)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Access the class's Conv2D_0 layer.\n",
        "        conv2D_0 = vars(self)['conv2D_0']\n",
        "        \n",
        "        # Connect the Conv2D_0 layer to inputs\n",
        "        x = conv2D_0(inputs)\n",
        "        \n",
        "        # For the remaining Conv2D_i layers from 1 to 'repetitions', they will be connected to previous layer.\n",
        "        for i in range(1, self.repetitions):\n",
        "            # Access Conv2D_i by formatting the integer 'i'.\n",
        "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
        "            \n",
        "            # Use the Conv2D_i instance and connect it to the previous layer\n",
        "            x = conv2D_i(x)\n",
        "            \n",
        "        # Finally, add the max_pool layer.\n",
        "        max_pool = self.max_pool(x)\n",
        "        \n",
        "        return max_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT8bGT5ePXYF"
      },
      "source": [
        "class MyVGG(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(MyVGG, self).__init__()\n",
        "        \n",
        "        # Creating blocks of VGG with the following (filters, kernel_size, repetitions) configurations\n",
        "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n",
        "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n",
        "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n",
        "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        \n",
        "        # Classification head\n",
        "        # Define a Flatten layer\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        \n",
        "        # Create a Dense layer with 256 units and ReLU activation function\n",
        "        self.fc = tf.keras.layers.Dense(256, activation='relu')\n",
        "        \n",
        "        # Finally, add the softmax classifier using a Dense layer\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Chain all the layers one after the other\n",
        "        x = self.block_a(inputs)\n",
        "        x = self.block_b(x)\n",
        "        x = self.block_c(x)\n",
        "        x = self.block_d(x)\n",
        "        x = self.block_e(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV3P4qlnPZq_",
        "outputId": "fa893964-b8e4-4cfc-e9e0-68ad01778d03"
      },
      "source": [
        "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')\n",
        "\n",
        "# Initialize VGG with the number of classes \n",
        "vgg = MyVGG(num_classes=2)\n",
        "\n",
        "# Compile with losses and metrics\n",
        "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define preprocessing function\n",
        "def preprocess(features):\n",
        "    # Resize and normalize\n",
        "    image = tf.image.resize(features['image'], (224, 224))\n",
        "    return tf.cast(image, tf.float32) / 255., features['label']\n",
        "\n",
        "# Apply transformations to dataset\n",
        "dataset = dataset.map(preprocess).batch(32)\n",
        "\n",
        "# Train the custom VGG model\n",
        "vgg.fit(dataset, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "727/727 [==============================] - 91s 124ms/step - loss: 0.6911 - accuracy: 0.5241\n",
            "Epoch 2/50\n",
            "727/727 [==============================] - 89s 123ms/step - loss: 0.6643 - accuracy: 0.6162\n",
            "Epoch 3/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.6368 - accuracy: 0.6462\n",
            "Epoch 4/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.6182 - accuracy: 0.6652\n",
            "Epoch 5/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.6054 - accuracy: 0.6742\n",
            "Epoch 6/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5958 - accuracy: 0.6834\n",
            "Epoch 7/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5880 - accuracy: 0.6870\n",
            "Epoch 8/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5812 - accuracy: 0.6927\n",
            "Epoch 9/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5749 - accuracy: 0.6976\n",
            "Epoch 10/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5690 - accuracy: 0.7040\n",
            "Epoch 11/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5634 - accuracy: 0.7098\n",
            "Epoch 12/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5581 - accuracy: 0.7118\n",
            "Epoch 13/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5529 - accuracy: 0.7167\n",
            "Epoch 14/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5479 - accuracy: 0.7207\n",
            "Epoch 15/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5430 - accuracy: 0.7251\n",
            "Epoch 16/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5382 - accuracy: 0.7288\n",
            "Epoch 17/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5336 - accuracy: 0.7313\n",
            "Epoch 18/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5290 - accuracy: 0.7346\n",
            "Epoch 19/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5245 - accuracy: 0.7389\n",
            "Epoch 20/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5202 - accuracy: 0.7422\n",
            "Epoch 21/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5159 - accuracy: 0.7451\n",
            "Epoch 22/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5117 - accuracy: 0.7489\n",
            "Epoch 23/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5075 - accuracy: 0.7515\n",
            "Epoch 24/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.5035 - accuracy: 0.7550\n",
            "Epoch 25/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4995 - accuracy: 0.7580\n",
            "Epoch 26/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4956 - accuracy: 0.7605\n",
            "Epoch 27/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4917 - accuracy: 0.7632\n",
            "Epoch 28/50\n",
            "727/727 [==============================] - 89s 123ms/step - loss: 0.4878 - accuracy: 0.7667\n",
            "Epoch 29/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4841 - accuracy: 0.7688\n",
            "Epoch 30/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4803 - accuracy: 0.7725\n",
            "Epoch 31/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4766 - accuracy: 0.7741\n",
            "Epoch 32/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4729 - accuracy: 0.7764\n",
            "Epoch 33/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4693 - accuracy: 0.7793\n",
            "Epoch 34/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4657 - accuracy: 0.7814\n",
            "Epoch 35/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4621 - accuracy: 0.7843\n",
            "Epoch 36/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4586 - accuracy: 0.7854\n",
            "Epoch 37/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4551 - accuracy: 0.7881\n",
            "Epoch 38/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4517 - accuracy: 0.7902\n",
            "Epoch 39/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4484 - accuracy: 0.7924\n",
            "Epoch 40/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4451 - accuracy: 0.7943\n",
            "Epoch 41/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4419 - accuracy: 0.7965\n",
            "Epoch 42/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4388 - accuracy: 0.7992\n",
            "Epoch 43/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4357 - accuracy: 0.8014\n",
            "Epoch 44/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4326 - accuracy: 0.8036\n",
            "Epoch 45/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4297 - accuracy: 0.8048\n",
            "Epoch 46/50\n",
            "727/727 [==============================] - 89s 123ms/step - loss: 0.4267 - accuracy: 0.8056\n",
            "Epoch 47/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4239 - accuracy: 0.8067\n",
            "Epoch 48/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4211 - accuracy: 0.8079\n",
            "Epoch 49/50\n",
            "727/727 [==============================] - 89s 122ms/step - loss: 0.4183 - accuracy: 0.8087\n",
            "Epoch 50/50\n",
            "727/727 [==============================] - 89s 123ms/step - loss: 0.4155 - accuracy: 0.8107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6b59e23150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3eGjhqqPbsA",
        "outputId": "03d545b3-d010-473e-e65c-591bb5c72ced"
      },
      "source": [
        "vgg.evaluate(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "727/727 [==============================] - 90s 123ms/step - loss: 0.5566 - accuracy: 0.7136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5566273331642151, 0.7136101722717285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvIUpMHPUimm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}